version: "3.9"

services:
  backend:
    build: ./10_backend
    container_name: caf_backend
    ports:
      - "8000:8000"

  

  app_front:
    build: ./20_frontend_user
    container_name: caf_front_user
    ports:
      - "5173:5173"

  admin_front:
    build: ./21_frontend_admin
    container_name: caf_front_admin
    ports:
      - "5174:5174"

  nginx:
    build: ./30_nginx
    container_name: caf_nginx
    ports:
      - "80:80"
    depends_on:
      - backend
      - ml_next
      - ml_fraud
      - llm_category
      - llm_analysis

  ml_next:
    build: ./40_ml_next
    container_name: caf_ml_next
    env_file:
      - ./40_ml_next/.env      # ⬅ 이 폴더에 .env 만들기
    ports:
      - "9001:9001"

  ml_fraud:
    build: ./41_ml_fraud
    container_name: caf_ml_fraud
    env_file:
      - ./41_ml_fraud/.env     # ⬅ 여기에도 .env
    ports:
      - "9002:9002"

  llm_category:
    build: ./50_llm_category
    container_name: caf_llm_category
    # env_file:
    #   - ./50_llm_category/.env
    ports:
      - "9100:9100"

  llm_analysis:
    build: ./51_llm_analysis
    container_name: caf_llm_analysis
    # env_file:
    #   - ./51_llm_analysis/.env
    ports:
      - "9101:9101"

  # (옵션) CLEO 챗봇 LLM 쓸 거면
  # llm_cleo:
  #   build: ./52_llm_cleo
  #   container_name: caf_llm_cleo
  #   # env_file:
  #   #   - ./52_llm_cleo/.env
  #   ports:
  #     - "9103:9103"
